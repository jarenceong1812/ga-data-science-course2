{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "In this first project you will create a framework to scope out data science projects. This framework will provide you with a guide to develop a well-articulated problem statement and analysis plan that will be robust and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and evaluate the following problem statement: \n",
    "Determine which free-tier customers will covert to paying customers, using demographic data collected at signup (age, gender, location, and profession) and customer useage data (days since last log in, and activity score 1 = active user, 0= inactive user) based on Hooli data from Jan-Apr 2015. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: free-tier customers converting to paying customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: age, gender, location, and profession and customer useage data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Jan-Apr 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Out of the predictors being age, gender, location, and profession and customer useage data, which one of them has association with free-tier customers converting into paying customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started with our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions_data = pd.read_csv('/Users/Jarence/desktop/ds-sg-04/projects/unit-projects/project-1/assets/admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige  prestige_1.0  prestige_2.0  prestige_3.0  \\\n",
       "0      0  380.0  3.61       3.0             0             0             1   \n",
       "1      1  660.0  3.67       3.0             0             0             1   \n",
       "2      1  800.0  4.00       1.0             1             0             0   \n",
       "3      1  640.0  3.19       4.0             0             0             0   \n",
       "4      0  520.0  2.93       4.0             0             0             0   \n",
       "5      1  760.0  3.00       2.0             0             1             0   \n",
       "6      1  560.0  2.98       1.0             1             0             0   \n",
       "7      0  400.0  3.08       2.0             0             1             0   \n",
       "8      1  540.0  3.39       3.0             0             0             1   \n",
       "9      0  700.0  3.92       2.0             0             1             0   \n",
       "\n",
       "   prestige_4.0  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  \n",
       "5             0  \n",
       "6             0  \n",
       "7             0  \n",
       "8             0  \n",
       "9             0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>2.486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa    prestige\n",
       "count  400.000000  398.000000  398.00000  399.000000\n",
       "mean     0.317500  588.040201    3.39093    2.486216\n",
       "std      0.466087  115.628513    0.38063    0.945333\n",
       "min      0.000000  220.000000    2.26000    1.000000\n",
       "25%      0.000000  520.000000    3.13000    2.000000\n",
       "50%      0.000000  580.000000    3.39500    2.000000\n",
       "75%      1.000000  660.000000    3.67000    3.000000\n",
       "max      1.000000  800.000000    4.00000    4.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>2.486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa    prestige\n",
       "count  400.000000  398.000000  398.00000  399.000000\n",
       "mean     0.317500  588.040201    3.39093    2.486216\n",
       "std      0.466087  115.628513    0.38063    0.945333\n",
       "min      0.000000  220.000000    2.26000    1.000000\n",
       "25%      0.000000  520.000000    3.13000    2.000000\n",
       "50%      0.000000  580.000000    3.39500    2.000000\n",
       "75%      1.000000  660.000000    3.67000    3.000000\n",
       "max      1.000000  800.000000    4.00000    4.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit         0.466087\n",
       "gre         115.628513\n",
       "gpa           0.380630\n",
       "prestige      0.945333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prestige_dummies = pd.get_dummies(admissions_data['prestige'], prefix = \"prestige\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admissions_data = pd.concat([admissions_data, prestige_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0             0             0             1             0\n",
       "1             0             0             1             0\n",
       "2             1             0             0             0\n",
       "3             0             0             0             1\n",
       "4             0             0             0             1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prestige_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige  prestige_1.0  prestige_2.0  prestige_3.0  \\\n",
       "0      0  380.0  3.61       3.0             0             0             1   \n",
       "1      1  660.0  3.67       3.0             0             0             1   \n",
       "2      1  800.0  4.00       1.0             1             0             0   \n",
       "3      1  640.0  3.19       4.0             0             0             0   \n",
       "4      0  520.0  2.93       4.0             0             0             0   \n",
       "\n",
       "   prestige_4.0  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182919</td>\n",
       "      <td>0.175952</td>\n",
       "      <td>-0.241355</td>\n",
       "      <td>0.203651</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>-0.121800</td>\n",
       "      <td>-0.133356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.182919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>-0.124533</td>\n",
       "      <td>0.087546</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>-0.075340</td>\n",
       "      <td>-0.069701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.175952</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059031</td>\n",
       "      <td>0.069595</td>\n",
       "      <td>-0.054744</td>\n",
       "      <td>0.072956</td>\n",
       "      <td>-0.085888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <td>-0.241355</td>\n",
       "      <td>-0.124533</td>\n",
       "      <td>-0.059031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.668727</td>\n",
       "      <td>-0.399701</td>\n",
       "      <td>0.359014</td>\n",
       "      <td>0.720266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_1.0</th>\n",
       "      <td>0.203651</td>\n",
       "      <td>0.087546</td>\n",
       "      <td>0.069595</td>\n",
       "      <td>-0.668727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328580</td>\n",
       "      <td>-0.279354</td>\n",
       "      <td>-0.190274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2.0</th>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>-0.054744</td>\n",
       "      <td>-0.399701</td>\n",
       "      <td>-0.328580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.510113</td>\n",
       "      <td>-0.347449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3.0</th>\n",
       "      <td>-0.121800</td>\n",
       "      <td>-0.075340</td>\n",
       "      <td>0.072956</td>\n",
       "      <td>0.359014</td>\n",
       "      <td>-0.279354</td>\n",
       "      <td>-0.510113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.295397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_4.0</th>\n",
       "      <td>-0.133356</td>\n",
       "      <td>-0.069701</td>\n",
       "      <td>-0.085888</td>\n",
       "      <td>0.720266</td>\n",
       "      <td>-0.190274</td>\n",
       "      <td>-0.347449</td>\n",
       "      <td>-0.295397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 admit       gre       gpa  prestige  prestige_1.0  \\\n",
       "admit         1.000000  0.182919  0.175952 -0.241355      0.203651   \n",
       "gre           0.182919  1.000000  0.382408 -0.124533      0.087546   \n",
       "gpa           0.175952  0.382408  1.000000 -0.059031      0.069595   \n",
       "prestige     -0.241355 -0.124533 -0.059031  1.000000     -0.668727   \n",
       "prestige_1.0  0.203651  0.087546  0.069595 -0.668727      1.000000   \n",
       "prestige_2.0  0.059627  0.057174 -0.054744 -0.399701     -0.328580   \n",
       "prestige_3.0 -0.121800 -0.075340  0.072956  0.359014     -0.279354   \n",
       "prestige_4.0 -0.133356 -0.069701 -0.085888  0.720266     -0.190274   \n",
       "\n",
       "              prestige_2.0  prestige_3.0  prestige_4.0  \n",
       "admit             0.059627     -0.121800     -0.133356  \n",
       "gre               0.057174     -0.075340     -0.069701  \n",
       "gpa              -0.054744      0.072956     -0.085888  \n",
       "prestige         -0.399701      0.359014      0.720266  \n",
       "prestige_1.0     -0.328580     -0.279354     -0.190274  \n",
       "prestige_2.0      1.000000     -0.510113     -0.347449  \n",
       "prestige_3.0     -0.510113      1.000000     -0.295397  \n",
       "prestige_4.0     -0.347449     -0.295397      1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit           0.787051\n",
       "gre            -0.150127\n",
       "gpa            -0.211765\n",
       "prestige        0.093663\n",
       "prestige_1.0    1.940499\n",
       "prestige_2.0    0.518344\n",
       "prestige_3.0    0.863169\n",
       "prestige_4.0    1.787539\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit          -1.387513\n",
       "gre            -0.330065\n",
       "gpa            -0.574623\n",
       "prestige       -0.894759\n",
       "prestige_1.0    1.774383\n",
       "prestige_2.0   -1.740045\n",
       "prestige_3.0   -1.261271\n",
       "prestige_4.0    1.201277\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11ed676d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11ecf0190>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x11f650d10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11f5e6810>]], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK5wTvZlZ4ZzozcwK50RvZla4/wenATVaTjU/oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed679d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prestige_dummies.hist(bins= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit               0.217237\n",
       "gre             13369.953040\n",
       "gpa                 0.144879\n",
       "prestige            0.893654\n",
       "prestige_1.0        0.129568\n",
       "prestige_2.0        0.234962\n",
       "prestige_3.0        0.211523\n",
       "prestige_4.0        0.139793\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57870093984e-13\n"
     ]
    }
   ],
   "source": [
    "statistic, pvalue = stats.ttest_ind(admissions_data[\"prestige_1.0\"], admissions_data[\"prestige_2.0\"], equal_var=False)\n",
    "print pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.08533866159e-06\n"
     ]
    }
   ],
   "source": [
    "statistic, pvalue = stats.ttest_ind(admissions_data[\"prestige_3.0\"], admissions_data[\"prestige_4.0\"], equal_var=False)\n",
    "print pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grades = smf.ols(formula='admit ~ gpa + gre + prestige', data=admissions_data).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>admit</td>      <th>  R-squared:         </th> <td>   0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 17 Jun 2017</td> <th>  Prob (F-statistic):</th> <td>1.65e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:06:50</td>     <th>  Log-Likelihood:    </th> <td> -239.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   397</td>      <th>  AIC:               </th> <td>   488.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   393</td>      <th>  BIC:               </th> <td>   503.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.1610</td> <td>    0.218</td> <td>   -0.737</td> <td> 0.462</td> <td>   -0.591     0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>       <td>    0.1462</td> <td>    0.064</td> <td>    2.296</td> <td> 0.022</td> <td>    0.021     0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>       <td>    0.0004</td> <td>    0.000</td> <td>    2.063</td> <td> 0.040</td> <td> 2.05e-05     0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige</th>  <td>   -0.1097</td> <td>    0.024</td> <td>   -4.606</td> <td> 0.000</td> <td>   -0.156    -0.063</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>191.690</td> <th>  Durbin-Watson:     </th> <td>   1.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  51.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.670</td>  <th>  Prob(JB):          </th> <td>7.02e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.855</td>  <th>  Cond. No.          </th> <td>6.02e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   R-squared:                       0.095\n",
       "Model:                            OLS   Adj. R-squared:                  0.088\n",
       "Method:                 Least Squares   F-statistic:                     13.69\n",
       "Date:                Sat, 17 Jun 2017   Prob (F-statistic):           1.65e-08\n",
       "Time:                        12:06:50   Log-Likelihood:                -239.99\n",
       "No. Observations:                 397   AIC:                             488.0\n",
       "Df Residuals:                     393   BIC:                             503.9\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.1610      0.218     -0.737      0.462        -0.591     0.269\n",
       "gpa            0.1462      0.064      2.296      0.022         0.021     0.271\n",
       "gre            0.0004      0.000      2.063      0.040      2.05e-05     0.001\n",
       "prestige      -0.1097      0.024     -4.606      0.000        -0.156    -0.063\n",
       "==============================================================================\n",
       "Omnibus:                      191.690   Durbin-Watson:                   1.939\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.364\n",
       "Skew:                           0.670   Prob(JB):                     7.02e-12\n",
       "Kurtosis:                       1.855   Cond. No.                     6.02e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.02e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admission into the school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: gre, gpa, prestige 1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: the current year graduates scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Which of the following, gre, gpa, prestige 1,2,3 or 4 is closely associated to getting admitted into the school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using the above information, write a well-formed problem statement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lab from a class as a guide, create an exploratory analysis plan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the goals of the exploratory analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: Tohelp me get a better understanding of\n",
    "my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. What are the assumptions of the distribution of data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. How will determine the distribution of your data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: By testing the dataset using skewness and kurtosis, i will be able to understand whether it is normally distributed. If the skew and kurt is closer to zero, it probably means that the data is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. How might outliers impact your analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: Outliers causes associations to be influenced by another confounding factor. It hides the true association between causes and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. How will you test for outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We make use of the Directed Acyclic Graph (DAG). It will help to visually demonstrate the logic of my models. From the (DAG), i will then be able to find out if there are other factors associated or affecting my depending variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. What is colinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer:  it means that two or more predictor variables in a multiple regression model are highly correlated, meaning that one can be linearly predicted from the others with a substantial degree of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. How will you test for colinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Using the one of the three test. Firstly, anova test which assumes normal distributions and equal variances in the two data sets. Secondly, The Welch t-test which assumes normal distributions but not necessarily equal variances, and accounts for small sample sizes better and lastly, the Mann-Whitney test which assumes nothing about the distributions but requires at least 20 data points in each set, and produces a weaker p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is your exploratory analysis plan?\n",
    "Using the above information, write an exploratory analysis plan that would allow you or a colleague to reproduce your analysis 1 year from now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Firstly, i will make use of the NumPy and Pandas libraries to analyze datasets using basic\n",
    "summary statistic figures like for example: mean, median, mode, max, min, quartile, interquartile\n",
    "range, variance, standard deviation, and correlation. Once that is done, i will proceed to create line graphs, box plots, and histograms, this is to discern characteristics and trends in my dataset. This step is considered as parsing the data. Moving on, i will have to figure out the distribution of my dataset, this can be done by using the skewness and kurtosis test. Once that is done, i will have to craft out a Directed Acyclic Graph to help me determine which variables are most important for my model. The (DAG) will also allow me to identify other factors that have association or impact on my depending variable which are also called outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions:\n",
    "1. Outline your analysis method for predicting your outcome\n",
    "2. Write an alternative problem statement for your dataset\n",
    "3. Articulate the assumptions and risks of the alternative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
